{
 "metadata": {
  "name": "pycon"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "source": [
      "# A Beginners Introduction to Pydata: How to Build a Minimal Recommendation System"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "## Environment setup\n",
      "### mac\n",
      "### win\n",
      "### lin"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "## The recommendation problem\n",
      "### Some definitions from the literature\n",
      "\n",
      "*In a typical recommender system people provide recommendations as inputs, which\n",
      "the system then aggregates and directs to appropriate recipients.* -- Resnick\n",
      "and Varian, 1997\n",
      "\n",
      "*Collaborative filtering simply means that people collaborate to help one\n",
      "another perform filtering by recording their reactions to documents they read.*\n",
      "-- Goldberg et al, 1992\n",
      "\n",
      "*In its most common formulation, the recommendation problem is reduced to the\n",
      "problem of estimating ratings for the items that have not been seen by a\n",
      "user. Intuitively, this estimation is usually based on the ratings given by this\n",
      "user to other items and on some other information [...] Once we can estimate\n",
      "ratings for the yet unrated items, we can recommend to the user the item(s) with\n",
      "the highest estimated rating(s).* -- Adomavicius and Tuzhilin, 2005\n"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "### Some notation\n",
      "\n",
      "- $U$ is the set of users in our domain. Its size is $|U|$.\n",
      "- $I$ is the set of items in our domain. Its size is $|I|$.\n",
      "- $I(u)$ is the set of items that user $u$ has rated/purchased.\n",
      "- $-I(u)$ is the complement of $I(u)$ i.e., the set of items not yet seen by user $u$.\n",
      "- $U(i)$ is the set of users that have rated/purchased item $i$.\n",
      "- $-U(i)$ is the complement of $U(i)$."
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "### Goal of a recommendation system\n",
      "$$ \\forall{u \\in U},\\; i^* = argmax_{i \\in -I(u)} [S(u,i)] $$"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "### Problem statement\n",
      "The recommendation problem in its most basic form is quite simple to define:\n",
      "\n",
      "```\n",
      "|---+---+---+---+---|\n",
      "| ? | ? | 4 | ? | 1 |\n",
      "|---+---+---+---+---|\n",
      "| 3 | ? | ? | 2 | 2 |\n",
      "|---+---+---+---+---|\n",
      "| 3 | ? | ? | ? | ? |\n",
      "|---+---+---+---+---|\n",
      "| ? | 1 | 2 | 1 | 1 |\n",
      "|---+---+---+---+---|\n",
      "| ? | ? | ? | ? | ? |\n",
      "|---+---+---+---+---|\n",
      "| 2 | ? | 2 | ? | ? |\n",
      "|---+---+---+---+---|\n",
      "| ? | ? | ? | ? | ? |\n",
      "|---+---+---+---+---|\n",
      "| 3 | 1 | 5 | ? | ? |\n",
      "|---+---+---+---+---|\n",
      "| ? | ? | ? | ? | 2 |\n",
      "|---+---+---+---+---|\n",
      "```\n",
      "\n",
      "*Given a partially filled matrix of ratings ($|U|x|I|$), estimate the missing values.*\n"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "### Content-based filtering\n",
      "\n",
      "Generic expression (notice how this is kind of a 'row-based' approach):\n",
      "\n",
      "$$ r_{u,i} = aggr_{i' \\in I(u)} [r_{u,i'}] $$\n"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "### Simple ratrings-based recommendations\n",
      "\n",
      "$$ r_{u,i} = \\bar r_u = \\frac{\\sum_{i \\in I(u)} r_{u,i}}{|I(u)|} $$\n"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "#### Generalizations of the aggregation function\n",
      "\n",
      "$$ r_{u,i} = k \\sum_{i' \\in I(u)} sim(i, i') \\; r_{u,i'} $$\n",
      "\n",
      "$$ r_{u,i} = \\bar r_u + k \\sum_{i' \\in I(u)} sim(i, i') \\; (r_{u,i'} - \\bar r_u) $$\n",
      "\n",
      "Here $k$ is a normalizing factor,\n",
      "\n",
      "$$ k = \\frac{1}{\\sum_{i' \\in I(u)} |sim(i,i')|} $$\n",
      "\n",
      "and $\\bar r_u$ is the average rating of user u:\n",
      "\n",
      "$$ \\bar r_u = \\frac{\\sum_{i \\in I(u)} r_{u,i}}{|I(u)|} $$\n"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "### Collaborative filtering\n",
      "\n",
      "Generic expression (notice how this is kind of a 'col-based' approach):\n",
      "\n",
      "$$ r_{u,i} = aggr_{u' \\in U(i)} [r_{u',i}] $$"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "### Simple ratrings-based recommendations\n",
      "\n",
      "$$ r_{u,i} = \\bar r_i = \\frac{1}{N} \\sum_{u' \\in U(i)} r_{u',i} $$\n"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "#### Generalizations of the aggregation function\n",
      "\n",
      "$$ r_{u,i} = k \\sum_{u' \\in U(i)} sim(u, u') \\; r_{u',i} $$\n",
      "\n",
      "$$ r_{u,i} = \\bar r_u + k \\sum_{u' \\in U(i)} sim(u, u') \\; (r_{u',i} - \\bar r_u) $$\n",
      "\n",
      "Here $k$ is a normalizing factor,\n",
      "\n",
      "$$ k = \\frac{1}{\\sum_{u' \\in U(i)} |sim(u,u')|} $$\n",
      "\n",
      "and $\\bar r_u$ is the average rating of user u:\n",
      "\n",
      "$$ \\bar r_u = \\frac{\\sum_{i \\in I(u)} r_{u,i}}{|I(u)|} $$"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "### Hybrid solutions\n",
      "\n",
      "The literature has lots of examples of systems that try to combine the strengths\n",
      "of the two main approaches. This can be done in a number of ways:\n",
      "\n",
      "- Combine the predictions of a content-based system and a collaborative system.\n",
      "- Incorporate content-based techniques into a collaborative approach.\n",
      "- Incorporarte collaborative techniques into a content-based approach.\n",
      "- Unifying model.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "### Challenges\n",
      "\n",
      "#### Availability of item metadata\n",
      "\n",
      "Content-based techniques are limited by the amount of metadata that is available\n",
      "to describe an item. There are domains in which feature extraction methods are\n",
      "expensive or time consuming, e.g., processing multimedia data such as graphics,\n",
      "audio/video streams. In the context of grocery items for example, it's often the\n",
      "case that item information is only partial or completely missing. Examples\n",
      "include:\n",
      "\n",
      "- Ingredients\n",
      "- Nutrition facts\n",
      "- Brand\n",
      "- Description\n",
      "- County of origin\n",
      "\n",
      "#### New user problem\n",
      "\n",
      "A user has to have rated a sufficient number of items before a recommender\n",
      "system can have a good idea of what their preferences are. In a content-based\n",
      "system, the aggregation function needs ratings to aggregate.\n",
      "\n",
      "#### New item problem\n",
      "\n",
      "Collaborative filters rely on an item being rated by many users to compute\n",
      "aggregates of those ratings. Think of this as the exact counterpart of the new\n",
      "user problem for content-based systems.\n",
      "\n",
      "#### Data sparsity\n",
      "\n",
      "When looking at the more general versions of content-based and collaborative\n",
      "systems, the success of the recommender system depends on the availability of a\n",
      "critical mass of user/item iteractions. We get a first glance at the data\n",
      "sparsity problem by quantifying the ratio of existing ratings vs $|U|x|I|$. A\n",
      "highly sparse matrix of interactions makes it difficult to compute similarities\n",
      "between users and items. As an example, for a user whose tastes are unusual\n",
      "compared to the rest of the population, there will not be any other users who\n",
      "are particularly similar, leading to poor recommendations.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "## Roadmap for this tutorial\n",
      "\n",
      "What exactly are we going to do?\n",
      "\n",
      "### Goal\n",
      "\n",
      "The goal of this tutorial is to provide you with a hands-on overview\n",
      "of a few of the libraries from the scientific and data analysis\n",
      "communities. We're going to use\n",
      "\n",
      "- numpy -- [numpy.org](http://www.numpy.org)\n",
      "- pandas -- [pandas.pydata.org/](http://pandas.pydata.org/)\n",
      "- matplotlib -- [matplotlib.org](http://matplotlib.org)\n",
      "- pytables -- [pytables.org](http://www.pytables.org)\n",
      "- (a little bit of) scipy -- [scipy.org](http://www.scipy.org)\n",
      "- (a little bit of) scikits-learn -- [scikit-learn.org](http://scikit-learn.org)\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "### Description of the datasets we're going to use\n",
      "\n",
      "We'll use the MovieLens dataset and another dataset from an online grocery\n",
      "store. \n"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "### Flow chart: the big picture\n"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "## NumPy: Numerical Python\n",
      "\n",
      "### What is it?\n",
      "\n",
      "\"It is a Python library that provides a multidimensional array object, various\n",
      "derived objects (such as masked arrays and matrices), and an assortment of\n",
      "routines for fast operations on arrays, including mathematical, logical, shape\n",
      "manipulation, sorting, selecting, I/O, discrete Fourier transforms, basic linear\n",
      "algebra, basic statistical operations, random simulation and much more.\""
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "### NumPy's basic data structure: the ndarray\n",
      "\n",
      "Think of ndarrays as the building blocks for pydata. A multidimensional array\n",
      "object that acts as a container for data to be passed between algorithms. Also,\n",
      "libraries written in a lower-level language, such as C or Fortran, can operate\n",
      "on the data stored in a NumPy array without copying any data.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "# set some print options\n",
      "np.set_printoptions(precision=4)\n",
      "np.set_printoptions(threshold=5)\n",
      "\n",
      "# build an array using the array function\n",
      "arr = np.array([0, 9, 5.055, 4, 3])\n",
      "arr"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 116,
       "text": [
        "array([ 0.   ,  9.   ,  5.055,  4.   ,  3.   ])"
       ]
      }
     ],
     "prompt_number": 116
    },
    {
     "cell_type": "markdown",
     "source": [
      "### Array creation examples\n",
      "\n",
      "There are several functions that are used to create new arrays:\n",
      "- np.array\n",
      "- np.asarray\n",
      "- np.arange\n",
      "- np.ones\n",
      "- np.ones_like\n",
      "- np.zeros\n",
      "- np.zeros_like"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.zeros(4)\n"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 117,
       "text": [
        "array([ 0.,  0.,  0.,  0.])"
       ]
      }
     ],
     "prompt_number": 117
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.ones(4)"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 118,
       "text": [
        "array([ 1.,  1.,  1.,  1.])"
       ]
      }
     ],
     "prompt_number": 118
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.empty(4)"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 119,
       "text": [
        "array([  6.9308e-310,   6.9308e-310,   2.1936e-314,   2.7814e-309])"
       ]
      }
     ],
     "prompt_number": 119
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.arange(4)"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 120,
       "text": [
        "array([0, 1, 2, 3])"
       ]
      }
     ],
     "prompt_number": 120
    },
    {
     "cell_type": "markdown",
     "source": [
      "### dtype and shape\n",
      "\n",
      "NumPy's arrays are containers of homogeneous data, which means all elements are\n",
      "of the same type. The 'dtype' propery is an object that specifies the data type\n",
      "of each element. The 'shape' property is a tuple that indicates the size of each\n",
      "dimension."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "arr.dtype"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "dtype('float64')"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "arr.shape"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "(5,)"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# you can be explicit about the data type that you want\n",
      "np.empty(4, dtype=np.int32)"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 121,
       "text": [
        "array([         0, 1879048192, 1515921094, -268433415], dtype=int32)"
       ]
      }
     ],
     "prompt_number": 121
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.array(['numpy','pandas','pytables'], dtype=np.string_)"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 122,
       "text": [
        "array(['numpy', 'pandas', 'pytables'], \n",
        "      dtype='|S8')"
       ]
      }
     ],
     "prompt_number": 122
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "float_arr = np.array([4.4, 5.52425, -0.1234, 98.1], dtype=np.float64)\n",
      "# truncate the decimal part\n",
      "float_arr.astype(np.int32)\n"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 123,
       "text": [
        "array([ 4,  5,  0, 98], dtype=int32)"
       ]
      }
     ],
     "prompt_number": 123
    },
    {
     "cell_type": "markdown",
     "source": [
      "### A note on structure: why this is important\n",
      "describes type, sizeof, byte order, record, subarray"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "### Vectorization\n",
      "\n",
      "Vectorization is at the heart of NumPy and it enables us to express operations\n",
      "without writing any for loops.  Operations between arrays with equal shapes are\n",
      "performed element-wise.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "arr = np.array([0, 9, 1.02, 4, 32])\n",
      "arr - arr"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 124,
       "text": [
        "array([ 0.,  0.,  0.,  0.,  0.])"
       ]
      }
     ],
     "prompt_number": 124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "arr * arr"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 125,
       "text": [
        "array([    0.    ,    81.    ,     1.0404,    16.    ,  1024.    ])"
       ]
      }
     ],
     "prompt_number": 125
    },
    {
     "cell_type": "markdown",
     "source": [
      "### Broadcasting Rules\n",
      "\n",
      "Vectorized operations between arrays of different sizes and between arrays and\n",
      "scalars are subject to the rules of broadcasting. The idea is quite simple in\n",
      "many cases:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "5 * arr "
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 126,
       "text": [
        "array([   0. ,   45. ,    5.1,   20. ,  160. ])"
       ]
      }
     ],
     "prompt_number": 126
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "10 + arr"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 127,
       "text": [
        "array([ 10.  ,  19.  ,  11.02,  14.  ,  42.  ])"
       ]
      }
     ],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "arr ** .5"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 128,
       "text": [
        "array([ 0.    ,  3.    ,  1.01  ,  2.    ,  5.6569])"
       ]
      }
     ],
     "prompt_number": 128
    },
    {
     "cell_type": "markdown",
     "source": [
      "### Indexing and slicing\n",
      "#### Just what you would expect from Python"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "arr[3]"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 129,
       "text": [
        "4.0"
       ]
      }
     ],
     "prompt_number": 129
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "arr[1:3]"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 130,
       "text": [
        "array([ 9.  ,  1.02])"
       ]
      }
     ],
     "prompt_number": 130
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# set the last two elements to 555\n",
      "arr[-2:] = 555\n",
      "arr"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 131,
       "text": [
        "array([   0.  ,    9.  ,    1.02,  555.  ,  555.  ])"
       ]
      }
     ],
     "prompt_number": 131
    },
    {
     "cell_type": "markdown",
     "source": [
      "#### Indexing behaviour for multidimensional arrays\n",
      "\n",
      "A good way to think about indexing in multidimensional arrays is that you are\n",
      "moving along the values of the shape property. So, a 4d array `arr_4d`, with a\n",
      "shape of `(w,x,y,z)` will result in indexed views such that:\n",
      "\n",
      "- `arr_4d[i].shape == (x,y,z)`\n",
      "- `arr_4d[i,j].shape == (y,z)`\n",
      "- `arr_4d[i,j,k].shape == (z,)`\n",
      "\n",
      "For the case of slices, what you are doing is selecting a range of elements\n",
      "along a particular axis:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "arr_2d = np.array([[5,3,4],[0,1,2],[1,1,10],[0,0,0.1]])\n",
      "# get the first row\n",
      "arr_2d[0]"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 152,
       "text": [
        "array([ 5.,  3.,  4.])"
       ]
      }
     ],
     "prompt_number": 152
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get the first column\n",
      "arr_2d[:,0]"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 153,
       "text": [
        "array([ 5.,  0.,  1.,  0.])"
       ]
      }
     ],
     "prompt_number": 153
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get the first two rows\n",
      "arr_2d[:2]"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 154,
       "text": [
        "array([[ 5.,  3.,  4.],\n",
        "       [ 0.,  1.,  2.]])"
       ]
      }
     ],
     "prompt_number": 154
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get the last element of the last two rows\n",
      "arr_2d[-2:, -1]"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 155,
       "text": [
        "array([ 10. ,   0.1])"
       ]
      }
     ],
     "prompt_number": 155
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# try this for higher dimensions\n",
      "arr_3d = np.array([[[2,2,2],[3,3,3]],[[1,1,1],[9,9,9]]])\n",
      "arr_3d[0]"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 156,
       "text": [
        "array([[2, 2, 2],\n",
        "       [3, 3, 3]])"
       ]
      }
     ],
     "prompt_number": 156
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get the last column of each matrix in this 3d array\n",
      "arr_3d[:,:,0]"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 143,
       "text": [
        "array([[2, 3],\n",
        "       [1, 9]])"
       ]
      }
     ],
     "prompt_number": 143
    },
    {
     "cell_type": "markdown",
     "source": [
      "#### Careful, it's a view!\n",
      "\n",
      "A slice does not return a copy, which means that any modifications will be\n",
      "reflected in the source array. This is a design feature of NumPy to avoid memory\n",
      "problems."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "slice = arr[2:4]\n",
      "slice[1] = 999.44\n",
      "arr"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 134,
       "text": [
        "array([   0.  ,    9.  ,    1.02,  999.44,  555.  ])"
       ]
      }
     ],
     "prompt_number": 134
    },
    {
     "cell_type": "markdown",
     "source": [
      "#### Boolean indexing\n",
      "\n",
      "Boolean indexing allows you to select data subsets of an array that satisfy a\n",
      "given condition."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "arr = np.array([123, 456])\n",
      "idx = np.array([True, False])\n",
      "arr[idx]\n"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 164,
       "text": [
        "array([123])"
       ]
      }
     ],
     "prompt_number": 164
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "arr_2d = np.random.randn(4,8)\n",
      "arr_2d\n"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 189,
       "text": [
        "array([[ 0.1489, -0.898 ,  1.3965, ...,  0.9804, -0.5942,  0.1053],\n",
        "       [ 2.2101, -1.4203,  0.2588, ..., -0.0629, -0.1697, -0.7688],\n",
        "       [ 0.815 , -0.0655,  0.4645, ...,  1.9024,  2.188 ,  0.6973],\n",
        "       [ 1.3895, -1.5447,  0.6398, ..., -0.7336,  0.4404,  0.1051]])"
       ]
      }
     ],
     "prompt_number": 189
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "arr_2d < 0"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 190,
       "text": [
        "array([[False,  True, False, ..., False,  True, False],\n",
        "       [False,  True, False, ...,  True,  True,  True],\n",
        "       [False,  True, False, ..., False, False, False],\n",
        "       [False,  True, False, ...,  True, False, False]], dtype=bool)"
       ]
      }
     ],
     "prompt_number": 190
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "arr_2d[arr_2d < 0]"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 191,
       "text": [
        "array([-0.898 , -0.3596, -0.4059, ..., -1.5447, -1.3029, -0.7336])"
       ]
      }
     ],
     "prompt_number": 191
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "arr_2d[arr_2d < 0] = 0\n",
      "arr_2d"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 192,
       "text": [
        "array([[ 0.1489,  0.    ,  1.3965, ...,  0.9804,  0.    ,  0.1053],\n",
        "       [ 2.2101,  0.    ,  0.2588, ...,  0.    ,  0.    ,  0.    ],\n",
        "       [ 0.815 ,  0.    ,  0.4645, ...,  1.9024,  2.188 ,  0.6973],\n",
        "       [ 1.3895,  0.    ,  0.6398, ...,  0.    ,  0.4404,  0.1051]])"
       ]
      }
     ],
     "prompt_number": 192
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "arr_2d[arr_2d.sum(axis=1) > 2.5]"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 198,
       "text": [
        "array([[ 0.1489,  0.    ,  1.3965, ...,  0.9804,  0.    ,  0.1053],\n",
        "       [ 0.815 ,  0.    ,  0.4645, ...,  1.9024,  2.188 ,  0.6973],\n",
        "       [ 1.3895,  0.    ,  0.6398, ...,  0.    ,  0.4404,  0.1051]])"
       ]
      }
     ],
     "prompt_number": 198
    },
    {
     "cell_type": "markdown",
     "source": [
      "#### Fancy indexing\n",
      "\n",
      "Fancy indexing is indexing with integer arrays."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "arr = np.arange(18).reshape(6,3)\n",
      "arr"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 200,
       "text": [
        "array([[ 0,  1,  2],\n",
        "       [ 3,  4,  5],\n",
        "       [ 6,  7,  8],\n",
        "       [ 9, 10, 11],\n",
        "       [12, 13, 14],\n",
        "       [15, 16, 17]])"
       ]
      }
     ],
     "prompt_number": 200
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# fancy selection of rows in a particular order\n",
      "arr[[0,4,4]]"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 218,
       "text": [
        "array([[ 0,  1,  2],\n",
        "       [12, 13, 14],\n",
        "       [12, 13, 14]])"
       ]
      }
     ],
     "prompt_number": 218
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# index into individual elements and flatten\n",
      "arr[[5,3,1],[2,1,0]]"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 216,
       "text": [
        "array([17, 10,  3])"
       ]
      }
     ],
     "prompt_number": 216
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# select a submatrix\n",
      "arr[np.ix_([5,3,1],[2,1])]"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 217,
       "text": [
        "array([[17, 16],\n",
        "       [11, 10],\n",
        "       [ 5,  4]])"
       ]
      }
     ],
     "prompt_number": 217
    },
    {
     "cell_type": "markdown",
     "source": [
      "Different from the concept of views, selecting data from an array by boolean or\n",
      "fancy indexing always creates a copy of the data, even if the returned array is\n",
      "unchanged."
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "### Arbitrary data-types"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "## The MovieLens Dataset: let's implement basic content and collaborative filters\n",
      "\n",
      "The code to load the data is from \"Python for Data Analysis\", a great book on\n",
      "these topics that I highly recommend.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "\n",
      "unames = ['user_id', 'gender', 'age', 'occupation', 'zip']\n",
      "users = pd.read_table('data/ml-1m/users.dat',\n",
      "                      sep='::', header=None, names=unames)\n",
      "\n",
      "rnames = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
      "ratings = pd.read_table('data/ml-1m/ratings.dat',\n",
      "                        sep='::', header=None, names=rnames)\n",
      "\n",
      "mnames = ['movie_id', 'title', 'genres']\n",
      "movies = pd.read_table('data/ml-1m/movies.dat',\n",
      "                       sep='::', header=None, names=mnames)\n",
      "\n",
      "# transform the frame into a ratings matrix and savetxt it\n",
      "ratings_subset = ratings[:10000]\n",
      "ratings_mtx_df = ratings_subset.pivot_table(values='rating',rows='user_id',cols='movie_id')\n",
      "ratings_mtx = ratings_mtx_df.as_matrix()\n",
      "np.savetxt('data/movielens_ratings_mtx.csv', ratings_mtx, fmt='%.1f', delimiter=',')\n"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "source": [
      "Load the ratings matrix from MovieLens and look around."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# do this to get floating point when dividing integers\n",
      "from __future__ import division\n",
      "\n",
      "ratings_mtx = np.loadtxt('data/movielens_ratings_mtx.csv', delimiter=',')\n",
      "ratings_density = ratings_mtx[ratings_mtx >= 1].size / ratings_mtx.size\n",
      "ratings_sparsity = 1 - ratings_density\n",
      "print ratings_mtx.shape\n",
      "print ratings_mtx[:4]\n",
      "print \"Density is %f and sparsity is %f\" % (ratings_density, ratings_sparsity)"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(70, 2159)\n",
        "[[  5.  nan  nan ...,  nan  nan  nan]\n",
        " [ nan  nan  nan ...,  nan  nan  nan]\n",
        " [ nan  nan  nan ...,  nan  nan  nan]\n",
        " [ nan  nan  nan ...,  nan  nan  nan]]\n",
        "Density is 0.066168 and sparsity is 0.933832\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "source": [
      "### Basic evaluation of our recommendation techniques\n",
      "\n",
      "Let's write up a routine to extract training and test sets from the ratings\n",
      "matrix. We'll then use this to evaluate our different recommendation techniques."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import cross_validation\n",
      "\n",
      "# get non-nan entries\n",
      "mask = ratings_mtx >= 1\n",
      "\n",
      "# make copies of the original mtx\n",
      "ratings_mtx_train = ratings_mtx.copy()\n",
      "ratings_mtx_test  = ratings_mtx.copy()\n",
      "\n",
      "for u_number, row in enumerate(ratings_mtx[:1]):\n",
      "    # show intermediate steps to get this user's ratings\n",
      "    print 'Mask for user %d is %s' % (u_number, mask[u_number])\n",
      "    \n",
      "    movie_ids = np.where(mask[u_number])[0] # same as mask[u_number].nonzero()[0]\n",
      "    print 'Movie ids that user %d rated are %s' % (u_number, movie_ids)\n",
      "    \n",
      "    user_ratings = row[mask[u_number]]\n",
      "    print 'Ratings given by user %d are %s' % (u_number, user_ratings)\n",
      "\n",
      "    # split ratings into training and test sets\n",
      "    X_train, X_test, y_train, y_test = cross_validation.train_test_split(\n",
      "        movie_ids, user_ratings, test_size=0.2, random_state=0)\n",
      "    print 'Movie ids for testing for user %d are %s' % (u_number, X_test)\n",
      "\n",
      "    # supress test entries from the train mtx\n",
      "    ratings_mtx_train[u_number, X_test] = np.nan\n",
      "    # suppress train entries from the test mtx\n",
      "    ratings_mtx_test[u_number, X_train] = np.nan\n",
      "\n",
      "# show sparsity numbers for the train matrix\n",
      "train_density = ratings_mtx_train[ratings_mtx_train >= 1].size / ratings_mtx_train.size\n",
      "train_sparsity = 1 - train_density\n",
      "print \"Density is %f and sparsity is %f\" % (train_density, train_sparsity)\n",
      "\n"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Mask for user 0 is [ True False False ..., False False False]\n",
        "Movie ids that user 0 rated are [   0   39   87 ..., 1749 1780 1882]\n",
        "Ratings given by user 0 are [ 5.  5.  5. ...,  4.  4.  4.]\n",
        "Movie ids for testing for user 0 are [1508 1022 1285 ...,  868  718  333]\n",
        "Density is 0.066095 and sparsity is 0.933905\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compute_rmse(y_pred, y_true):\n",
      "    \"\"\" Compute Root Mean Squared Error. \"\"\"\n",
      "    return np.sqrt(np.mean(np.power(y_pred - y_true, 2)))"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "source": [
      "### Content-based filtering using mean ratings\n",
      "\n",
      "Let's write this out on a per-user basis so that we illustrate what we referred\n",
      "to as the 'row-based' approach.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import cross_validation\n",
      "\n",
      "# get non-nan entries\n",
      "train_mask = ratings_mtx_train >= 1\n",
      "test_mask  = ratings_mtx_test  >= 1\n",
      "\n",
      "for u_number, row in enumerate(ratings_mtx_train[:1]):\n",
      "    # show intermediate steps to get this user's ratings\n",
      "    print 'Mask for user %d is %s' % (u_number, train_mask[u_number])\n",
      "    \n",
      "    movie_ids = np.where(train_mask[u_number])[0] # same as mask[u_number].nonzero()[0]\n",
      "    print 'Movie ids that user %d rated are %s' % (u_number, movie_ids)\n",
      "    \n",
      "    user_ratings = row[train_mask[u_number]]\n",
      "    print 'Ratings given by user %d are %s' % (u_number, user_ratings)\n",
      "\n",
      "    # compute mean rating for this user\n",
      "    mean_rating = np.mean(user_ratings)\n",
      "    print 'Mean rating for user %s is %s' % (u_number, mean_rating)\n",
      "\n",
      "    # evaluate performance of our recommendation technique\n",
      "    rmse = compute_rmse(mean_rating,\n",
      "                        ratings_mtx_test[u_number, ratings_mtx_test[u_number]>=1])\n",
      "    print 'RMSE for user %d is %f' % (u_number, rmse)\n",
      "        "
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Mask for user 0 is [ True False False ..., False False False]\n",
        "Movie ids that user 0 rated are [   0   39  159 ..., 1749 1780 1882]\n",
        "Ratings given by user 0 are [ 5.  5.  4. ...,  4.  4.  4.]\n",
        "Mean rating for user 0 is 4.16666666667\n",
        "RMSE for user 0 is 0.757121\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# don't know whether to use this cell atm -- keep for now\n",
      "# create new dtypes to hold ratings and id information\n",
      "dt = np.dtype([('rating', np.float64), ('ids', np.int32, (2,))])\n",
      "print dt['rating'].__repr__()\n",
      "print dt['ids'].__repr__()\n",
      "\n",
      "# get row,col that are not nan\n",
      "not_nan = ~np.isnan(ratings_mtx_train) # equivalent to ratings_mtx_train >= 1\n",
      "not_nan_ids = zip(*not_nan.nonzero())\n",
      "\n",
      "# build an array with ratings and their user, item ids\n",
      "ratings_train = np.array(zip(ratings_mtx_train[not_nan], not_nan_ids), dtype=dt)\n",
      "ratings_train[:4]\n",
      "\n"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "dtype('float64')\n",
        "dtype(('int32',(2,)))\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 82,
       "text": [
        "array([(5.0, [0, 0]), (5.0, [0, 47]), (4.0, [0, 253]), (4.0, [0, 517])], \n",
        "      dtype=[('rating', '<f8'), ('ids', '<i4', (2,))])"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "markdown",
     "source": [
      "### Content-based filtering using mean ratings: overall evaluation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def estimate0(ids):\n",
      "    \"\"\" Simple content-filtering based on mean ratings. \"\"\"\n",
      "\n",
      "    def func1d(arr):\n",
      "        return np.mean(arr[arr>=1])\n",
      "\n",
      "    return np.apply_along_axis(func1d, 1, ratings_mtx_train[ids[0]])\n",
      "\n",
      "def estimate1(ids):\n",
      "    \"\"\" Simple content-filtering based on mean ratings. \"\"\"\n",
      "    estimates = []\n",
      "    for user_id in ids[0]:\n",
      "        estimates.append(\n",
      "            np.mean(\n",
      "                ratings_mtx_train[user_id,\n",
      "                                  ratings_mtx_train[user_id]>=1]\n",
      "                ))\n",
      "\n",
      "    return np.array(estimates)\n",
      "\n",
      "def estimate2(ids):\n",
      "    \"\"\" Simple content-filtering based on mean ratings. \"\"\"\n",
      "    from scipy.stats.stats import nanmean\n",
      "    \n",
      "    estimates = []\n",
      "    for user_id in ids[0]:\n",
      "        estimates.append(nanmean(ratings_mtx_train[user_id]))\n",
      "\n",
      "    return np.array(estimates)\n",
      "\n",
      "def estimate3(ids):\n",
      "    \"\"\" Simple content-filtering based on mean ratings. \"\"\"\n",
      "    from scipy.stats.stats import nanmean\n",
      "    \n",
      "    estimates = nanmean(ratings_mtx_train[ids[0]], axis=1)\n",
      "    return estimates\n",
      "\n",
      "def evaluate(estimate_f):\n",
      "    \"\"\" Simple content-filtering based on mean ratings. \"\"\"\n",
      "    non_nan_ids = np.where(~np.isnan(ratings_mtx_test))\n",
      "    estimated = estimate_f(non_nan_ids)\n",
      "    real = ratings_mtx_test[non_nan_ids]\n",
      "    return compute_rmse(estimated, real)\n",
      "\n",
      "%time print 'RMSE for estimate0: %s' % evaluate(estimate0)\n",
      "%time print 'RMSE for estimate1: %s' % evaluate(estimate1)\n",
      "%time print 'RMSE for estimate2: %s' % evaluate(estimate2)\n",
      "%time print 'RMSE for estimate3: %s' % evaluate(estimate3)\n"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RMSE for estimate0 0.997385212165\n",
        "CPU times: user 1.16 s, sys: 0.07 s, total: 1.23 s\n",
        "Wall time: 1.23 s\n",
        "RMSE for estimate1 0.997385212165"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "CPU times: user 0.55 s, sys: 0.00 s, total: 0.56 s\n",
        "Wall time: 0.56 s\n",
        "RMSE for estimate2 0.997385212165"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "CPU times: user 1.02 s, sys: 0.00 s, total: 1.02 s\n",
        "Wall time: 1.03 s\n",
        "RMSE for estimate3 0.997385212165"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "CPU times: user 1.80 s, sys: 0.28 s, total: 2.08 s\n",
        "Wall time: 2.08 s\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "markdown",
     "source": [
      "### Collaborative-based filtering using mean ratings\n",
      "\n",
      "Same idea, this time to illustrate the 'col-based' approach.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def estimate4(ids):\n",
      "    \"\"\" Simple collaborative filter based on mean ratings. \"\"\"\n",
      "    estimates = []\n",
      "    for item_id in ids[1]:\n",
      "        estimates.append(\n",
      "            np.mean(\n",
      "                ratings_mtx_train[ratings_mtx_train[:, item_id]>=1,\n",
      "                                  item_id]\n",
      "                ))\n",
      "\n",
      "    return np.array(estimates)\n",
      "\n",
      "def estimate5(ids):\n",
      "    \"\"\" Simple collaborative filter based on mean ratings. \"\"\"\n",
      "    return estimate1(    \n",
      "\n",
      "%time print 'RMSE for estimate:4 %s' % evaluate(estimate4)\n"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RMSE for estimate4 0.851885677236\n",
        "CPU times: user 0.28 s, sys: 0.00 s, total: 0.28 s\n",
        "Wall time: 0.28 s\n"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "markdown",
     "source": [
      "One more twist: using the same estimate function, but with more arguments. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def estimate1_with_args(ids, ratings_mtx_train):\n",
      "    \"\"\" Simple content-filtering based on mean ratings. \"\"\"\n",
      "    estimates = []\n",
      "    for user_id in ids[0]:\n",
      "        estimates.append(\n",
      "            np.mean(\n",
      "                ratings_mtx_train[user_id,\n",
      "                                  ratings_mtx_train[user_id]>=1]\n",
      "                ))\n",
      "\n",
      "    return np.array(estimates)\n",
      "\n",
      "non_nan_ids = np.where(~np.isnan(ratings_mtx_test))\n",
      "estimated = estimate1_with_args(non_nan_ids, ratings_mtx_train)\n",
      "real = ratings_mtx_test[non_nan_ids]\n",
      "print 'RMSE for estimate1_with_args (row-based): %s' % compute_rmse(estimated, real)\n",
      "estimated = estimate1_with_args((non_nan_ids[1], non_nan_ids[0]),\n",
      "                                ratings_mtx_train.T)\n",
      "print 'RMSE for estimate1_with_args (col-based): %s' %compute_rmse(estimated, real)"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RMSE for estimate1_with_args (row-based): 0.997385212165\n",
        "RMSE for estimate1_with_args (col-based): 0.851885677236"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "markdown",
     "source": [
      "To put things into perspective, here's an extract from The Netflix Prize Rules:\n",
      "\n",
      "*To qualify for the Grand Prize the RMSE of a Participant\u2019s submitted\n",
      "predictions on the test subset must be less than or equal to 90% of 0.9525, or\n",
      "0.8572 (the \"qualifying RMSE\").*"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "### More generic content-based recommendations"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def learn(X_train=None):\n",
      "    \"\"\" Build a content-based user profile. \"\"\"\n",
      "    self.user_profile = self.aggr(X_train)\n",
      "\n",
      "def estimate(X_test):\n",
      "    \"\"\" Compute scores for items in X_test. \"\"\"\n",
      "    return self.sim(self.user_profile, X_test)"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "source": [
      "## First look at our grocery domain dataset\n",
      "\n",
      "The first portion of our dataset is called an incidence matrix. This\n",
      "is a |U| x |I| matrix that shows the relationship between users and\n",
      "items. An entry in row u and column i is 1 if user u and item i are\n",
      "related, and zero if they are not. In our context, related means 'has\n",
      "ever purchased'."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "inc_mtx = np.loadtxt(open('data/inc_mtx_10k_1k.csv', 'r'), delimiter=',')\n",
      "inc_mtx.shape\n",
      "inc_mtx.size\n"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "source": [
      "Let's compute some basic stats from this matrix"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tot_sum = inc_mtx.sum()\n",
      "row_sum = inc_mtx.sum(axis=0) \n",
      "col_sum = inc_mtx.sum(axis=1)\n",
      "\n",
      "# ratio of ones and zeros to total entries\n",
      "density = tot_sum / inc_mtx.size\n",
      "sparsity = 1.0 - density\n",
      "\n",
      "# most popular item\n",
      "i_popular = np.argmax(row_sum)\n",
      "# user with the most purchases\n",
      "u_spender = np.argmax(col_sum)\n"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "source": [
      "## pandas: Python Data Analysis Library\n",
      "\n",
      "### What is it?\n",
      "\n",
      "*Python has long been great for data munging and preparation, but less so for\n",
      "data analysis and modeling. pandas helps fill this gap, enabling you to carry\n",
      "out your entire data analysis workflow in Python without having to switch to a\n",
      "more domain specific language like R.*\n",
      "\n",
      "The heart of pandas is the DataFrame object for data manipulation. It features:\n",
      "\n",
      "- a powerful index object\n",
      "- data alignment\n",
      "- handling of missing data\n",
      "- aggregation with groupby\n",
      "- data manipuation via reshape, pivot, slice, merge, join\n",
      "\n",
      "### Series: labelled arrays\n",
      "\n",
      "The pandas Series is the simplest datastructure to start with. It is a subclass\n",
      "of ndarray that supports more meaninful indices."
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "#### Let's look at some creation examples for Series"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "\n",
      "values = np.array([2.0, 1.0, 5.0, 0.97, 3.0, 10.0, 0.0599, 8.0])\n",
      "pd.Series(values)"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 292,
       "text": [
        "0     2.0000\n",
        "1     1.0000\n",
        "2     5.0000\n",
        "3     0.9700\n",
        "4     3.0000\n",
        "5    10.0000\n",
        "6     0.0599\n",
        "7     8.0000"
       ]
      }
     ],
     "prompt_number": 292
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "values = np.array([2.0, 1.0, 5.0, 0.97, 3.0, 10.0, 0.0599, 8.0])\n",
      "labels = ['Calcium', 'Dietary Fibre', 'Iron', 'Sodium', 'Protein', 'Carbohydrates', 'Potassium', 'Fat (Total)']\n",
      "ser = pd.Series(data=values, index=labels)\n",
      "ser\n"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 316,
       "text": [
        "Calcium           2.0000\n",
        "Dietary Fibre     1.0000\n",
        "Iron              5.0000\n",
        "Sodium            0.9700\n",
        "Protein           3.0000\n",
        "Carbohydrates    10.0000\n",
        "Potassium         0.0599\n",
        "Fat (Total)       8.0000"
       ]
      }
     ],
     "prompt_number": 316
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nutrition_facts = {\n",
      "    'Calcium': 2.0,\n",
      "    'Carbohydrates': 10.0,\n",
      "    'Dietary Fibre': 1.0,\n",
      "    'Fat (Total)': 8.0,\n",
      "    'Iron': 5.0,\n",
      "    'Potassium': 0.0599,\n",
      "    'Protein': 3.0,\n",
      "    'Sodium': 0.97\n",
      "}\n",
      "ser = pd.Series(nutrition_facts)\n",
      "ser\n"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 331,
       "text": [
        "Calcium           2.0000\n",
        "Carbohydrates    10.0000\n",
        "Dietary Fibre     1.0000\n",
        "Fat (Total)       8.0000\n",
        "Iron              5.0000\n",
        "Potassium         0.0599\n",
        "Protein           3.0000\n",
        "Sodium            0.9700"
       ]
      }
     ],
     "prompt_number": 331
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ser.index"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 332,
       "text": [
        "Index([Calcium, Carbohydrates, Dietary Fibre, ..., Potassium, Protein,\n",
        "       Sodium], dtype=object)"
       ]
      }
     ],
     "prompt_number": 332
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ser.values"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 333,
       "text": [
        "array([  2.    ,  10.    ,   1.    , ...,   0.0599,   3.    ,   0.97  ])"
       ]
      }
     ],
     "prompt_number": 333
    },
    {
     "cell_type": "markdown",
     "source": [
      "#### Series Indexing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ser[0]"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 334,
       "text": [
        "2.0"
       ]
      }
     ],
     "prompt_number": 334
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ser['Calcium']"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 335,
       "text": [
        "2.0"
       ]
      }
     ],
     "prompt_number": 335
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ser.get_value('Calcium')"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 336,
       "text": [
        "2.0"
       ]
      }
     ],
     "prompt_number": 336
    },
    {
     "cell_type": "markdown",
     "source": [
      "#### Operations between Series with different index objects"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ser_1 = pd.Series(data)\n",
      "values = np.array([77.0, 2.5])\n",
      "labels = ['Vitamin A', 'Calcium']\n",
      "ser_2 = pd.Series(values, index=labels)\n",
      "ser_1 + ser_2\n"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 301,
       "text": [
        "Calcium          4.5\n",
        "Carbohydrates    NaN\n",
        "Dietary Fibre    NaN\n",
        "Fat (Total)      NaN\n",
        "Iron             NaN\n",
        "Potassium        NaN\n",
        "Protein          NaN\n",
        "Sodium           NaN\n",
        "Vitamin A        NaN"
       ]
      }
     ],
     "prompt_number": 301
    },
    {
     "cell_type": "markdown",
     "source": [
      "### DataFrame\n",
      "\n",
      "The DataFrame is the 2-dimensional version of a Series.\n",
      "\n",
      "#### Let's look at some creation examples for DataFrame\n",
      "\n",
      "You can think of it as a spreadsheet whose columns are Series objects."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.DataFrame({'col_1': [0.12, 7, 45, 10], 'col_2': [0.9, 9, 34, 11]})\n",
      "df"
     ],
     "language": "python",
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\">\n",
        "  <thead>\n",
        "    <tr>\n",
        "      <th></th>\n",
        "      <th>prod_1</th>\n",
        "      <th>prod_2</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <td><strong>0</strong></td>\n",
        "      <td>  0.12</td>\n",
        "      <td>  0.9</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td><strong>1</strong></td>\n",
        "      <td>  7.00</td>\n",
        "      <td>  9.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td><strong>2</strong></td>\n",
        "      <td> 45.00</td>\n",
        "      <td> 34.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td><strong>3</strong></td>\n",
        "      <td> 10.00</td>\n",
        "      <td> 11.0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 338,
       "text": [
        "   prod_1  prod_2\n",
        "0    0.12     0.9\n",
        "1    7.00     9.0\n",
        "2   45.00    34.0\n",
        "3   10.00    11.0"
       ]
      }
     ],
     "prompt_number": 338
    },
    {
     "cell_type": "markdown",
     "source": [
      "You can also think of it as a dictionary of Series objects."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.DataFrame({'prod_1': ser_1, 'prod_2': ser_2})\n",
      "df"
     ],
     "language": "python",
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\">\n",
        "  <thead>\n",
        "    <tr>\n",
        "      <th></th>\n",
        "      <th>prod_1</th>\n",
        "      <th>prod_2</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <td><strong>Calcium</strong></td>\n",
        "      <td>  2.0000</td>\n",
        "      <td>  2.5</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td><strong>Carbohydrates</strong></td>\n",
        "      <td> 10.0000</td>\n",
        "      <td>  NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td><strong>Dietary Fibre</strong></td>\n",
        "      <td>  1.0000</td>\n",
        "      <td>  NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td><strong>Fat (Total)</strong></td>\n",
        "      <td>  8.0000</td>\n",
        "      <td>  NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td><strong>Iron</strong></td>\n",
        "      <td>  5.0000</td>\n",
        "      <td>  NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td><strong>Potassium</strong></td>\n",
        "      <td>  0.0599</td>\n",
        "      <td>  NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td><strong>Protein</strong></td>\n",
        "      <td>  3.0000</td>\n",
        "      <td>  NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td><strong>Sodium</strong></td>\n",
        "      <td>  0.9700</td>\n",
        "      <td>  NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td><strong>Vitamin A</strong></td>\n",
        "      <td>     NaN</td>\n",
        "      <td> 77.0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 340,
       "text": [
        "                prod_1  prod_2\n",
        "Calcium         2.0000     2.5\n",
        "Carbohydrates  10.0000     NaN\n",
        "Dietary Fibre   1.0000     NaN\n",
        "Fat (Total)     8.0000     NaN\n",
        "Iron            5.0000     NaN\n",
        "Potassium       0.0599     NaN\n",
        "Protein         3.0000     NaN\n",
        "Sodium          0.9700     NaN\n",
        "Vitamin A          NaN    77.0"
       ]
      }
     ],
     "prompt_number": 340
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "df = pd.read_csv('data/nutri_df_1k.csv')\n",
      "df"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 341,
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 1000 entries, 0 to 999\n",
        "Data columns:\n",
        "Unnamed: 0              1000  non-null values\n",
        "(Omega-3 Poly)          24  non-null values\n",
        "(Omega-6 Poly)          22  non-null values\n",
        "+ Trans Fat             99  non-null values\n",
        "Biotin (B)              0  non-null values\n",
        "Calcium                 15  non-null values\n",
        "Carbohydrates           507  non-null values\n",
        "Cholesterol             432  non-null values\n",
        "Dietary Fibre           270  non-null values\n",
        "Energy (Cal)            4  non-null values\n",
        "Fat (Total)             462  non-null values\n",
        "Folic Acid (B9)         16  non-null values\n",
        "Iron                    21  non-null values\n",
        "Lycopene                1  non-null values\n",
        "Magnesium               7  non-null values\n",
        "Monounsaturates         75  non-null values\n",
        "Niacin (B3)             16  non-null values\n",
        "Other Nutrients         0  non-null values\n",
        "Pantothenic Acid (B)    9  non-null values\n",
        "Phosphorus              7  non-null values\n",
        "Polyunsaturates         54  non-null values\n",
        "Potassium               149  non-null values\n",
        "Protein                 525  non-null values\n",
        "Pyridoxine (B6)         13  non-null values\n",
        "Riboflavin (B2)         14  non-null values\n",
        "Saturates               296  non-null values\n",
        "Serving Size            433  non-null values\n",
        "Sodium                  506  non-null values\n",
        "Starch                  27  non-null values\n",
        "Sugars                  326  non-null values\n",
        "Thiamine (B1)           15  non-null values\n",
        "Vitamin A               5  non-null values\n",
        "Vitamin B12             6  non-null values\n",
        "Vitamin C               0  non-null values\n",
        "Vitamin D               8  non-null values\n",
        "Vitamin E               0  non-null values\n",
        "Zinc                    11  non-null values\n",
        "dtypes: float64(36), int64(1)"
       ]
      }
     ],
     "prompt_number": 341
    },
    {
     "cell_type": "markdown",
     "source": [
      "## PyTables\n",
      "### What is it?"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "## misc - not yet green"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "items_mtx = np.array([[0.9,  0  , 0  ],  # viewed by 1\n",
      "                      [1,    0.1, 0.1],  # viewed by 1\n",
      "                      [0,    0.5, 0  ],  # viewed by 2\n",
      "                      [0.1,  0.4, 0  ],  # viewed by 2\n",
      "                      [0,    0.3, 0  ]])  # ?\n",
      "\n",
      "def aggr(mtx):\n",
      "  return np.mean(mtx)\n",
      "\n",
      "# build profiles\n",
      "user_1_profile = aggr(items_mtx[[0,1]])\n",
      "user_2_profile = aggr(items_mtx[[2,3]])\n",
      "\n",
      "\n",
      "def sim(v1, v2):\n",
      "  pass\n",
      "\n",
      "# recommend!\n",
      "estimated_rating_1_4 = sim(user_1_profile, items_mtx[4])"
     ],
     "language": "python",
     "outputs": []
    }
   ]
  }
 ]
}